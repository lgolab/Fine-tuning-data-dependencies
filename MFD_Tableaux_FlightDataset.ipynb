{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MFD-Tableaux-FlightDataset-github.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1wEDDnwIhhLnE08W1K6HxKQiUnwsDn32C",
      "authorship_tag": "ABX9TyNhIVrsq3ekT5MKp1uj8r5Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lgolab/Fine-tuning-data-dependencies/blob/main/MFD_Tableaux_FlightDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hiloX5prHQG"
      },
      "source": [
        "# 1. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGbe67HavHvi"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF5o9apUvLV3"
      },
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from itertools import chain, combinations"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFdsyawp3E2H"
      },
      "source": [
        "### Moving data to colab\n",
        "\n",
        "Please replace this part of code with downloading the data (including `August2018-Nationwide-flights.csv` and `AirCarriers`) and putting it in the `/content/flight` folder)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZq9nbRh0FKE",
        "outputId": "a5dfd8a8-e1ef-46ef-cc64-617c9dc00e31"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/FD-project/flight/ /content/flight\n",
        "%cd /content/flight/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/flight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnLWA3Ys3KRx"
      },
      "source": [
        "### Reading the data and Creating the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eutRQEvJbivd",
        "outputId": "39766c6a-c8f4-467b-d2b6-64135928e27c"
      },
      "source": [
        "dataset_address = 'August2018-Nationwide-flights.csv'\n",
        "\n",
        "attrs = ['FL_DATE', 'OP_CARRIER_AIRLINE_ID', 'OP_CARRIER_FL_NUM',\n",
        "         'ORIGIN', 'DEST',\n",
        "         'ORIGIN_CITY_MARKET_ID', 'DEST_CITY_MARKET_ID', \n",
        "         'DEP_DELAY', 'ARR_DELAY']\n",
        "attrIndex = []\n",
        "\n",
        "dataset = []\n",
        "with open(dataset_address) as csvfile:    \n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    \n",
        "    cnt = 0\n",
        "    \n",
        "    for row in reader:\n",
        "        if cnt == 0:\n",
        "            for attr in attrs:\n",
        "                attrIndex.append(row.index(attr))\n",
        "        else:\n",
        "            tupple = {}\n",
        "            for i in range(len(attrs)):\n",
        "                tupple[attrs[i]] = row[attrIndex[i]]\n",
        "            \n",
        "            dataset.append(tupple)\n",
        "                \n",
        "        cnt += 1\n",
        "    \n",
        "\n",
        "print('Number of tuples in dataset: ', len(dataset), '\\nA sample tuple:\\n', dataset[5])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tuples in dataset:  701352 \n",
            "A sample tuple:\n",
            " {'FL_DATE': '2018-08-01', 'OP_CARRIER_AIRLINE_ID': '19805', 'OP_CARRIER_FL_NUM': '1594', 'ORIGIN': 'DTW', 'DEST': 'ORD', 'ORIGIN_CITY_MARKET_ID': '31295', 'DEST_CITY_MARKET_ID': '30977', 'DEP_DELAY': '-10.00', 'ARR_DELAY': '-7.00'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KoumiZ4Sddw"
      },
      "source": [
        "### Filtering the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZSpMZF1Sht5",
        "outputId": "ecc41f83-b1d2-42c3-f0d7-1db2df33ca6d"
      },
      "source": [
        "US_major_airports = ['ATL', 'BOS', 'DEN', 'ORD', 'LAX', 'CLT', 'LAS', 'PHX', 'JFK', 'SEA']\n",
        "filter_dic = {\n",
        "        'ORIGIN': US_major_airports,    # 10/many!\n",
        "        'DEST': US_major_airports    # 10/many!\n",
        "}\n",
        "\n",
        "filtered_dataset = []\n",
        "for tupple in dataset:\n",
        "    filter_flag = 0\n",
        "    for key in filter_dic:\n",
        "        if tupple[key] not in filter_dic[key]:\n",
        "            filter_flag = 1\n",
        "    if not filter_flag:\n",
        "        filtered_dataset.append(tupple)\n",
        "\n",
        "print('Dataset size before filtering: ', len(dataset))\n",
        "print('Dataset size after filtering: ', len(filtered_dataset))\n",
        "dataset = filtered_dataset"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size before filtering:  701352\n",
            "Dataset size after filtering:  43266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAtM7LlQrBuh"
      },
      "source": [
        "### Making fields human-readable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMNXKWxArGNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6337c207-b7ec-4fc1-b36e-4bf77008c380"
      },
      "source": [
        "AirlineMap = {}\n",
        "with open('AirCarriers') as csvfile:    \n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    cnt = 0\n",
        "    \n",
        "    for row in reader:\n",
        "        if cnt != 0:\n",
        "            AirlineMap[row[0]] = row[1]\n",
        "        cnt += 1\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "    dataset[i]['OP_CARRIER_AIRLINE_ID'] = AirlineMap[dataset[i]['OP_CARRIER_AIRLINE_ID']]\n",
        "\n",
        "# Test:\n",
        "print(len(dataset))\n",
        "print(dataset[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43266\n",
            "{'FL_DATE': '2018-08-01', 'OP_CARRIER_AIRLINE_ID': 'American Airlines Inc.: AA', 'OP_CARRIER_FL_NUM': '1587', 'ORIGIN': 'JFK', 'DEST': 'PHX', 'ORIGIN_CITY_MARKET_ID': '31703', 'DEST_CITY_MARKET_ID': '30466', 'DEP_DELAY': '9.00', 'ARR_DELAY': '44.00'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuDEA2RONadw"
      },
      "source": [
        "# 2. Implementing CWCG algorithm\n",
        "\n",
        "The codes in this part can be applied on other datasets with the similar python dictionary format. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnNvjjRDrRQy"
      },
      "source": [
        "### Function for adding important patterns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KgmdoOWN4WH"
      },
      "source": [
        "def add_patterns(general_patterns):\n",
        "    global patterns, pattern_members, entry_patterns\n",
        "\n",
        "    pattern_tuples = {}\n",
        "    \n",
        "    for entry_index, entry in enumerate(dataset):\n",
        "        pattern_tuple = tuple([])\n",
        "        pattern_dictionary = {}\n",
        "        \n",
        "        for attr in general_patterns:\n",
        "            pattern_tuple = pattern_tuple + tuple([entry[attr]])\n",
        "            pattern_dictionary[attr] = entry[attr]\n",
        "        \n",
        "        if pattern_tuple not in pattern_tuples:\n",
        "            pattern_tuples[pattern_tuple] = len(patterns)\n",
        "            patterns.append(pattern_dictionary)\n",
        "            pattern_members.append([])\n",
        "        \n",
        "        pattern_index = pattern_tuples[pattern_tuple]\n",
        "        pattern_members[pattern_index].append(entry_index)\n",
        "        entry_patterns[entry_index].append(pattern_index)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-OLd_69xEod"
      },
      "source": [
        "### Functions for setting cost of patterns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zQhkl5xBf5V"
      },
      "source": [
        "def calculate_delta(arr, confidence = 0.9):\n",
        "    n = len(arr)\n",
        "    removals = n - round(n * confidence)\n",
        "    best_delta = arr[-1] - arr[0]\n",
        "\n",
        "    # removing outliers in such a way that minimize delta:\n",
        "    for i in range(removals+1):\n",
        "        best_delta = min(best_delta, arr[-(removals-i+1)] - arr[i])\n",
        "    \n",
        "    return best_delta"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj9AxvphxIrt"
      },
      "source": [
        "def calculate_costs(MFD_LHS_attrs, MFD_target, base = 2, confidence1 = 0.9, confidence2 = 1):\n",
        "    global pattern_costs, pattern_deltas\n",
        "    pattern_costs = [0 for i in range(len(patterns))]\n",
        "    pattern_deltas = [0 for i in range(len(patterns))]\n",
        "\n",
        "    inf = 1e8\n",
        "    eps = 0.5\n",
        "\n",
        "    # Calculating fixed-antecedent group deltas:\n",
        "\n",
        "    global group_deltas, group_members\n",
        "    group_deltas = {}\n",
        "    group_members = {}\n",
        "\n",
        "    for entry_index, entry in enumerate(dataset):\n",
        "        if not dataset[entry_index][MFD_target].replace('.','',1).replace('-','',1).isnumeric():\n",
        "            continue\n",
        "\n",
        "        group_tuple = tuple([])\n",
        "    \n",
        "        for attr in MFD_LHS_attrs:\n",
        "            group_tuple = group_tuple + tuple([entry[attr]])\n",
        "        \n",
        "        if group_tuple not in group_members:\n",
        "            group_members[group_tuple] = []\n",
        "        group_members[group_tuple].append(float(dataset[entry_index][MFD_target]))\n",
        "    \n",
        "    for group_tuple in group_members:\n",
        "        arr = group_members[group_tuple]\n",
        "        arr.sort()\n",
        "        group_deltas[group_tuple] = calculate_delta(arr, confidence=confidence1)\n",
        "\n",
        "\n",
        "    # Calculating pattern deltas: \n",
        "\n",
        "    for i, pattern in enumerate(patterns):\n",
        "\n",
        "        pattern_groups = set([])\n",
        "\n",
        "        for entry_index in pattern_members[i]:\n",
        "            if dataset[entry_index][MFD_target].replace('.','',1).replace('-','',1).isnumeric():\n",
        "                group_tuple = tuple([])\n",
        "\n",
        "                for attr in MFD_LHS_attrs:\n",
        "                    group_tuple = group_tuple + tuple([dataset[entry_index][attr]])\n",
        "\n",
        "                pattern_groups.add(group_tuple)\n",
        "\n",
        "                \n",
        "        if len(pattern_groups) == 0:\n",
        "            pattern_costs[i] = inf\n",
        "        else:\n",
        "            deltas = []\n",
        "            for group_tuple in pattern_groups:\n",
        "                deltas.append(group_deltas[group_tuple])\n",
        "            \n",
        "            deltas.sort()\n",
        "            n = len(deltas)\n",
        "            overall_delta = deltas[round(n * confidence2)-1] \n",
        "\n",
        "            pattern_deltas[i] = overall_delta\n",
        "\n",
        "            pattern_costs[i] = (base ** (overall_delta/15))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKsA-uW4wG7T"
      },
      "source": [
        "### CWSC function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9H8YHP0LZ4D"
      },
      "source": [
        "# In this function, we use dataset, patterns, pattern_members, entry_patterns, and patterns as global variables\n",
        "\n",
        "def CWSC(k, coverage):\n",
        "    \n",
        "    total_cost = 0\n",
        "\n",
        "    # Moving pattern_members to members\n",
        "    members = [set([]) for i in range(len(patterns))]\n",
        "    for i in range(len(patterns)):\n",
        "        for member in pattern_members[i]:\n",
        "            members[i].add(member)\n",
        "    \n",
        "    selected = [0 for i in range(len(patterns))]\n",
        "    solution_patterns = []\n",
        "    rem = int(len(dataset) * coverage)\n",
        "    \n",
        "    for i in range(k, 0, -1):\n",
        "        \n",
        "        max_gain = 0.0\n",
        "        max_pattern_index = -1\n",
        "        \n",
        "        for index, pattern in enumerate(patterns):\n",
        "            \n",
        "            marginal_benefit = len(members[index])\n",
        "            cost = pattern_costs[index]\n",
        "            marginal_gain = marginal_benefit / cost\n",
        "            \n",
        "            if selected[index] == 0 and marginal_benefit >= rem/i and marginal_gain > max_gain:\n",
        "                max_gain = marginal_gain\n",
        "                max_pattern_index = index\n",
        "        \n",
        "        if max_pattern_index == -1:\n",
        "            print('Impossible!')\n",
        "            return ['Failed!']\n",
        "        \n",
        "        # selecting the next pattern\n",
        "        selected[max_pattern_index] = 1\n",
        "        total_cost += pattern_costs[max_pattern_index]\n",
        "        solution_patterns.append(max_pattern_index)\n",
        "        rem -= len(members[max_pattern_index])\n",
        "\n",
        "        if rem <= 0:\n",
        "            print('\\nTotal cost is ', total_cost, '\\n')\n",
        "            return solution_patterns, total_cost\n",
        "        \n",
        "        # updating the marginal benefits\n",
        "        for entry_index in members[max_pattern_index]:\n",
        "            for pattern_index in entry_patterns[entry_index]:\n",
        "                if pattern_index != max_pattern_index:\n",
        "                    members[pattern_index].remove(entry_index)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRVyPQXWTJov"
      },
      "source": [
        "### Running the algorithm on the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42nV06tgrdZN"
      },
      "source": [
        "import timeit\n",
        "\n",
        "def generate_MFD_tableaux(MFD_LHS_attrs, MFD_target, k = 20, confidence = 0.9, coverage = 0.5):\n",
        "\n",
        "    # Adding patterns:\n",
        "    print('\\nAdding all the patterns... \\n')\n",
        "    t1 = timeit.default_timer()\n",
        "\n",
        "    global patterns, pattern_members, entry_patterns\n",
        "    patterns = []\n",
        "    pattern_members = []\n",
        "    entry_patterns = [[] for i in range(len(dataset))]\n",
        "\n",
        "    for x in chain.from_iterable(combinations(MFD_LHS_attrs, r) for r in range(0, len(MFD_LHS_attrs)+1)):\n",
        "        general_pattern = list(x)\n",
        "        print(general_pattern)\n",
        "        add_patterns(general_pattern)\n",
        "\n",
        "    t2 = timeit.default_timer()\n",
        "    print('\\nAdding patterns finished!\\n')\n",
        "    print('Time elapsed: ', t2-t1)\n",
        "\n",
        "    print('Number of patterns: ', len(patterns))\n",
        "    \n",
        "    # Calculating pattern costs:\n",
        "    print('\\nCalculating pattern costs...\\n')\n",
        "    calculate_costs(MFD_LHS_attrs, MFD_target, confidence1=confidence)\n",
        "\n",
        "    t3 = timeit.default_timer()\n",
        "    print('\\nCalculating pattern costs finished!\\n')\n",
        "    print('Time elapsed: ', t3-t2)\n",
        "\n",
        "    #Running CWSC algorithm:\n",
        "    print('\\nRunning CWSC algorithm...\\n')\n",
        "    solution_patterns, total_cost = CWSC(k, coverage)\n",
        "\n",
        "    t4 = timeit.default_timer()\n",
        "    print('Time elapsed: ', t4-t3, '\\n')\n",
        "    print('\\nTotal elapsed time: ', t4-t1, '\\n')\n",
        "\n",
        "    print('\\nTableaux:', '(size = ' + str(len(solution_patterns)) + ')\\n')\n",
        "    for pattern_index in solution_patterns:\n",
        "        print(patterns[pattern_index], 'delta:', pattern_deltas[pattern_index])\n",
        "\n",
        "    return solution_patterns, total_cost"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VK-ITI7X0i0",
        "outputId": "e63af50a-f073-4b1a-d68b-16d6be171000"
      },
      "source": [
        "# Generating MFD tableaux: \n",
        "solution_patterns, total_cost = generate_MFD_tableaux(\n",
        "    MFD_LHS_attrs = ['OP_CARRIER_AIRLINE_ID', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST'],\n",
        "    MFD_target = 'DEP_DELAY', \n",
        "    k = 50,\n",
        "    coverage = 0.6)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Adding all the patterns... \n",
            "\n",
            "[]\n",
            "['OP_CARRIER_AIRLINE_ID']\n",
            "['OP_CARRIER_FL_NUM']\n",
            "['ORIGIN']\n",
            "['DEST']\n",
            "['OP_CARRIER_AIRLINE_ID', 'OP_CARRIER_FL_NUM']\n",
            "['OP_CARRIER_AIRLINE_ID', 'ORIGIN']\n",
            "['OP_CARRIER_AIRLINE_ID', 'DEST']\n",
            "['OP_CARRIER_FL_NUM', 'ORIGIN']\n",
            "['OP_CARRIER_FL_NUM', 'DEST']\n",
            "['ORIGIN', 'DEST']\n",
            "['OP_CARRIER_AIRLINE_ID', 'OP_CARRIER_FL_NUM', 'ORIGIN']\n",
            "['OP_CARRIER_AIRLINE_ID', 'OP_CARRIER_FL_NUM', 'DEST']\n",
            "['OP_CARRIER_AIRLINE_ID', 'ORIGIN', 'DEST']\n",
            "['OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST']\n",
            "['OP_CARRIER_AIRLINE_ID', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST']\n",
            "\n",
            "Adding patterns finished!\n",
            "\n",
            "Time elapsed:  1.5219098739999026\n",
            "Number of patterns:  21775\n",
            "\n",
            "Calculating pattern costs...\n",
            "\n",
            "\n",
            "Calculating pattern costs finished!\n",
            "\n",
            "Time elapsed:  2.252412906000245\n",
            "\n",
            "Running CWSC algorithm...\n",
            "\n",
            "\n",
            "Total cost is  10680.360445154929 \n",
            "\n",
            "Time elapsed:  0.8655125029999908 \n",
            "\n",
            "\n",
            "Total elapsed time:  4.639835283000139 \n",
            "\n",
            "\n",
            "Tableaux: (size = 50)\n",
            "\n",
            "{'ORIGIN': 'LAX', 'DEST': 'SEA'} delta: 93.0\n",
            "{'ORIGIN': 'LAS', 'DEST': 'LAX'} delta: 100.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'American Airlines Inc.: AA', 'DEST': 'CLT'} delta: 112.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'United Air Lines Inc.: UA', 'ORIGIN': 'LAX'} delta: 98.0\n",
            "{'ORIGIN': 'ATL', 'DEST': 'LAX'} delta: 96.0\n",
            "{'ORIGIN': 'SEA', 'DEST': 'PHX'} delta: 94.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'American Airlines Inc.: AA', 'DEST': 'LAX'} delta: 114.0\n",
            "{'ORIGIN': 'CLT', 'DEST': 'ATL'} delta: 100.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'American Airlines Inc.: AA', 'DEST': 'DEN'} delta: 102.0\n",
            "{'ORIGIN': 'DEN', 'DEST': 'SEA'} delta: 110.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Alaska Airlines Inc.: AS', 'DEST': 'LAS'} delta: 95.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Delta Air Lines Inc.: DL', 'DEST': 'ORD'} delta: 96.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'American Airlines Inc.: AA', 'ORIGIN': 'LAX'} delta: 126.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Delta Air Lines Inc.: DL', 'DEST': 'BOS'} delta: 108.0\n",
            "{'ORIGIN': 'LAS', 'DEST': 'ATL'} delta: 93.0\n",
            "{'ORIGIN': 'DEN', 'DEST': 'ATL'} delta: 108.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Alaska Airlines Inc.: AS', 'ORIGIN': 'SEA'} delta: 128.0\n",
            "{'ORIGIN': 'ATL', 'DEST': 'CLT'} delta: 105.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'American Airlines Inc.: AA', 'ORIGIN': 'JFK'} delta: 114.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'American Airlines Inc.: AA', 'DEST': 'ORD'} delta: 144.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Delta Air Lines Inc.: DL', 'ORIGIN': 'LAX', 'DEST': 'ATL'} delta: 116.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Delta Air Lines Inc.: DL', 'DEST': 'LAS'} delta: 129.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Alaska Airlines Inc.: AS', 'DEST': 'SEA'} delta: 135.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'United Air Lines Inc.: UA', 'ORIGIN': 'LAS'} delta: 86.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'United Air Lines Inc.: UA', 'DEST': 'LAX'} delta: 131.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'American Airlines Inc.: AA', 'DEST': 'BOS'} delta: 135.0\n",
            "{'ORIGIN': 'PHX', 'DEST': 'ATL'} delta: 62.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Delta Air Lines Inc.: DL', 'ORIGIN': 'SEA', 'DEST': 'LAX'} delta: 90.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'American Airlines Inc.: AA', 'DEST': 'SEA'} delta: 125.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Delta Air Lines Inc.: DL', 'ORIGIN': 'ORD'} delta: 130.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'United Air Lines Inc.: UA', 'ORIGIN': 'PHX'} delta: 57.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'United Air Lines Inc.: UA', 'DEST': 'PHX'} delta: 112.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'American Airlines Inc.: AA', 'DEST': 'PHX'} delta: 148.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Delta Air Lines Inc.: DL', 'ORIGIN': 'ATL', 'DEST': 'DEN'} delta: 107.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'United Air Lines Inc.: UA', 'ORIGIN': 'ORD', 'DEST': 'BOS'} delta: 124.0\n",
            "{'ORIGIN': 'ATL', 'DEST': 'SEA'} delta: 125.0\n",
            "{'ORIGIN': 'BOS', 'DEST': 'LAX'} delta: 128.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Republic Airline: YX'} delta: 111.0\n",
            "{'ORIGIN': 'LAX', 'DEST': 'BOS'} delta: 115.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Delta Air Lines Inc.: DL', 'ORIGIN': 'JFK', 'DEST': 'LAX'} delta: 128.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'SkyWest Airlines Inc.: OO', 'ORIGIN': 'LAX'} delta: 95.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'American Airlines Inc.: AA', 'DEST': 'JFK'} delta: 147.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Delta Air Lines Inc.: DL', 'ORIGIN': 'LAS', 'DEST': 'SEA'} delta: 71.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Envoy Air: MQ'} delta: 78.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'SkyWest Airlines Inc.: OO', 'ORIGIN': 'PHX'} delta: 77.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'American Airlines Inc.: AA', 'ORIGIN': 'PHX', 'DEST': 'LAS'} delta: 80.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Compass Airlines: CP', 'ORIGIN': 'SEA', 'DEST': 'LAX'} delta: 84.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'United Air Lines Inc.: UA', 'ORIGIN': 'ATL'} delta: 69.0\n",
            "{'OP_CARRIER_AIRLINE_ID': 'United Air Lines Inc.: UA', 'ORIGIN': 'SEA', 'DEST': 'ORD'} delta: 85.0\n",
            "{'OP_CARRIER_FL_NUM': '805'} delta: 50.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEIz_H081Ey3"
      },
      "source": [
        "# 3. Baseline Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfBwwlBU1Ey3"
      },
      "source": [
        "def set_cover(coverage):\n",
        "    total_cost = 0\n",
        "\n",
        "    # Moving pattern_members to members\n",
        "    members = [set([]) for i in range(len(patterns))]\n",
        "    for i in range(len(patterns)):\n",
        "        for member in pattern_members[i]:\n",
        "            members[i].add(member)\n",
        "    \n",
        "    selected = [0 for i in range(len(patterns))]\n",
        "    solution_patterns = []\n",
        "    global banned_patterns\n",
        "    rem = int(len(dataset) * coverage)\n",
        "    \n",
        "    while True:\n",
        "        \n",
        "        max_support = 0\n",
        "        max_pattern_index = -1\n",
        "        \n",
        "        for index, pattern in enumerate(patterns):\n",
        "            \n",
        "            marginal_support = len(members[index])\n",
        "            \n",
        "            if banned_patterns[index] == 0 and selected[index] == 0 and marginal_support > max_support:\n",
        "                max_support = marginal_support\n",
        "                max_pattern_index = index\n",
        "        \n",
        "        if max_pattern_index == -1:\n",
        "            print('Impossible!')\n",
        "            return ['Failed!']\n",
        "        \n",
        "        # selecting the next pattern\n",
        "        selected[max_pattern_index] = 1\n",
        "        total_cost += pattern_costs[max_pattern_index]\n",
        "        solution_patterns.append(max_pattern_index)\n",
        "        rem -= len(members[max_pattern_index])\n",
        "\n",
        "        if rem <= 0:\n",
        "            print('\\nTotal cost is ', total_cost, '\\n')\n",
        "            return solution_patterns, total_cost\n",
        "        \n",
        "        # updating the marginal supports\n",
        "        for entry_index in members[max_pattern_index]:\n",
        "            for pattern_index in entry_patterns[entry_index]:\n",
        "                if pattern_index != max_pattern_index:\n",
        "                    members[pattern_index].remove(entry_index)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok7AMSitQQhS"
      },
      "source": [
        "import heapq\n",
        "\n",
        "def optimized_set_cover(coverage):\n",
        "    total_cost = 0\n",
        "\n",
        "    # Moving pattern_members to members\n",
        "    members = [set([]) for i in range(len(patterns))]\n",
        "    for i in range(len(patterns)):\n",
        "        for member in pattern_members[i]:\n",
        "            members[i].add(member)\n",
        "    \n",
        "    solution_patterns = []\n",
        "    global banned_patterns\n",
        "    rem = int(len(dataset) * coverage)\n",
        "\n",
        "    remaining_patterns = []\n",
        "    heapq.heapify(remaining_patterns)\n",
        "    for index, pattern in enumerate(patterns):\n",
        "        if banned_patterns[index] == 0:\n",
        "            heapq.heappush(remaining_patterns, (-len(members[index]), index))\n",
        "    \n",
        "    \n",
        "    while True:\n",
        "        \n",
        "        _, max_pattern_index = heapq.heappop(remaining_patterns)\n",
        "\n",
        "        # selecting the next pattern\n",
        "        total_cost += pattern_costs[max_pattern_index]\n",
        "        solution_patterns.append(max_pattern_index)\n",
        "        rem -= len(members[max_pattern_index])\n",
        "\n",
        "        if rem <= 0:\n",
        "            print('\\nTotal cost is ', total_cost, '\\n')\n",
        "            return solution_patterns, total_cost\n",
        "        \n",
        "        # updating the marginal supports\n",
        "        for entry_index in members[max_pattern_index]:\n",
        "            for pattern_index in entry_patterns[entry_index]:\n",
        "                if pattern_index != max_pattern_index and banned_patterns[pattern_index] == 0:\n",
        "                    remaining_patterns.pop(remaining_patterns.index((-len(members[pattern_index]), pattern_index)))\n",
        "                    members[pattern_index].remove(entry_index)\n",
        "                    heapq.heappush(remaining_patterns, (-len(members[pattern_index]), pattern_index))\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E62Av09F1Ey4"
      },
      "source": [
        "def generate_baseline_MFD_tableaux(MFD_LHS_attrs, MFD_target, max_delta, coverage = 0.6):\n",
        "\n",
        "    # Adding patterns:\n",
        "    print('\\nAdding all the patterns... \\n')\n",
        "\n",
        "    global patterns, pattern_members, entry_patterns \n",
        "    patterns = []\n",
        "    pattern_members = []\n",
        "    entry_patterns = [[] for i in range(len(dataset))]\n",
        "\n",
        "    for x in chain.from_iterable(combinations(MFD_LHS_attrs, r) for r in range(0, len(MFD_LHS_attrs)+1)):\n",
        "        general_pattern = list(x)\n",
        "        print(general_pattern)\n",
        "        add_patterns(general_pattern)\n",
        "\n",
        "    print('\\nAdding patterns finished!\\n')\n",
        "\n",
        "    print('Number of patterns: ', len(patterns))\n",
        "\n",
        "    # Calculating pattern costs:\n",
        "    print('\\nCalculating pattern costs...\\n')\n",
        "    calculate_costs(MFD_LHS_attrs, MFD_target)\n",
        "    print('\\nCalculating pattern costs finished!\\n')\n",
        "\n",
        "    global banned_patterns\n",
        "    banned_patterns = [0 for i in range(len(patterns))]\n",
        "    for i in range(len(patterns)):\n",
        "        if pattern_deltas[i] > max_delta:\n",
        "            banned_patterns[i] = 1\n",
        "\n",
        "    #Running set-cover algorithm:\n",
        "    print('\\nRunning set-cover algorithm...\\n')\n",
        "    solution_patterns, total_cost = set_cover(coverage)\n",
        "    print('\\nTableaux:', '(size = ' + str(len(solution_patterns)) + ')\\n')\n",
        "\n",
        "    for pattern_index in solution_patterns:\n",
        "        support = round(len(pattern_members[pattern_index])/len(dataset)*100, 2)\n",
        "        print(patterns[pattern_index], '\\tdelta:', pattern_deltas[pattern_index], ' support(%):', support)\n",
        "\n",
        "    return solution_patterns, total_cost"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hImBwk2-Wzil"
      },
      "source": [
        "def generate_optimized_baseline_MFD_tableaux(MFD_LHS_attrs, MFD_target, max_delta, coverage = 0.6):\n",
        "\n",
        "    # Adding patterns:\n",
        "    print('\\nAdding all the patterns... \\n')\n",
        "\n",
        "    global patterns, pattern_members, entry_patterns \n",
        "    patterns = []\n",
        "    pattern_members = []\n",
        "    entry_patterns = [[] for i in range(len(dataset))]\n",
        "\n",
        "    for x in chain.from_iterable(combinations(MFD_LHS_attrs, r) for r in range(0, len(MFD_LHS_attrs)+1)):\n",
        "        general_pattern = list(x)\n",
        "        print(general_pattern)\n",
        "        add_patterns(general_pattern)\n",
        "\n",
        "    print('\\nAdding patterns finished!\\n')\n",
        "\n",
        "    print('Number of patterns: ', len(patterns))\n",
        "\n",
        "    # Calculating pattern costs:\n",
        "    print('\\nCalculating pattern costs...\\n')\n",
        "    calculate_costs(MFD_LHS_attrs, MFD_target)\n",
        "    print('\\nCalculating pattern costs finished!\\n')\n",
        "\n",
        "    global banned_patterns\n",
        "    banned_patterns = [0 for i in range(len(patterns))]\n",
        "    for i in range(len(patterns)):\n",
        "        if pattern_deltas[i] > max_delta:\n",
        "            banned_patterns[i] = 1\n",
        "\n",
        "    #Running set-cover algorithm:\n",
        "    print('\\nRunning set-cover algorithm...\\n')\n",
        "    solution_patterns, total_cost = optimized_set_cover(coverage)\n",
        "    print('\\nTableaux:', '(size = ' + str(len(solution_patterns)) + ')\\n')\n",
        "\n",
        "    for pattern_index in solution_patterns:\n",
        "        support = round(len(pattern_members[pattern_index])/len(dataset)*100, 2)\n",
        "        print(patterns[pattern_index], '\\tdelta:', pattern_deltas[pattern_index], ' support(%):', support)\n",
        "\n",
        "    return solution_patterns, total_cost"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hvYpp2n1Ey4",
        "outputId": "f31b2b1f-4cbb-4399-c9bc-ed2d7aa6b994"
      },
      "source": [
        "# Gneerate MFD tableaux with the Baseline Algorithm:\n",
        "\n",
        "baseline_patterns, baseline_cost = generate_optimized_baseline_MFD_tableaux(\n",
        "    MFD_LHS_attrs = ['OP_CARRIER_AIRLINE_ID', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST'],\n",
        "    MFD_target = 'DEP_DELAY', \n",
        "    max_delta = 500,\n",
        "    coverage = 0.6)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Adding all the patterns... \n",
            "\n",
            "[]\n",
            "['OP_CARRIER_AIRLINE_ID']\n",
            "['OP_CARRIER_FL_NUM']\n",
            "['ORIGIN']\n",
            "['DEST']\n",
            "['OP_CARRIER_AIRLINE_ID', 'OP_CARRIER_FL_NUM']\n",
            "['OP_CARRIER_AIRLINE_ID', 'ORIGIN']\n",
            "['OP_CARRIER_AIRLINE_ID', 'DEST']\n",
            "['OP_CARRIER_FL_NUM', 'ORIGIN']\n",
            "['OP_CARRIER_FL_NUM', 'DEST']\n",
            "['ORIGIN', 'DEST']\n",
            "['OP_CARRIER_AIRLINE_ID', 'OP_CARRIER_FL_NUM', 'ORIGIN']\n",
            "['OP_CARRIER_AIRLINE_ID', 'OP_CARRIER_FL_NUM', 'DEST']\n",
            "['OP_CARRIER_AIRLINE_ID', 'ORIGIN', 'DEST']\n",
            "['OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST']\n",
            "['OP_CARRIER_AIRLINE_ID', 'OP_CARRIER_FL_NUM', 'ORIGIN', 'DEST']\n",
            "\n",
            "Adding patterns finished!\n",
            "\n",
            "Number of patterns:  21775\n",
            "\n",
            "Calculating pattern costs...\n",
            "\n",
            "\n",
            "Calculating pattern costs finished!\n",
            "\n",
            "\n",
            "Running set-cover algorithm...\n",
            "\n",
            "\n",
            "Total cost is  5927212.582298655 \n",
            "\n",
            "\n",
            "Tableaux: (size = 5)\n",
            "\n",
            "{'OP_CARRIER_AIRLINE_ID': 'American Airlines Inc.: AA'} \tdelta: 227.0  support(%): 24.62\n",
            "{'OP_CARRIER_AIRLINE_ID': 'United Air Lines Inc.: UA'} \tdelta: 320.0  support(%): 12.32\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Southwest Airlines Co.: WN'} \tdelta: 324.0  support(%): 12.14\n",
            "{'OP_CARRIER_AIRLINE_ID': 'Alaska Airlines Inc.: AS'} \tdelta: 161.0  support(%): 8.71\n",
            "{'OP_CARRIER_AIRLINE_ID': 'JetBlue Airways: B6'} \tdelta: 241.0  support(%): 7.76\n"
          ]
        }
      ]
    }
  ]
}